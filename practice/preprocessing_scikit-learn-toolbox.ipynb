{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217f111e-1090-482c-b281-40d6e3b998c4",
   "metadata": {},
   "source": [
    "# Preprocessing and Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51576d2-e40d-4548-9b73-d65ed9172ff4",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94981a2-b216-4d6c-afbe-1e2994a14a1a",
   "metadata": {},
   "source": [
    "### Creating dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2305fbd-5cc8-4188-9623-8d50328e964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "music_df = pd.read_csv('music.csv')\n",
    "music_dummies = pd.get_dummies(music_df[\"genre\"], drop_first=True)\n",
    "print(music_dummies.head())\n",
    "\n",
    "music_dummies = pd.concat([music_df, music_dummies], axis=1)\n",
    "music_dummies = music_dummies.drop(\"genre\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e6e2c-245a-4fb2-abfa-e70a1f62cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create music_dummies\n",
    "music_dummies = pd.get_dummies(music_df, drop_first=True)\n",
    "\n",
    "# Print the new DataFrame's shape\n",
    "print(\"Shape of music_dummies: {}\".format(music_dummies.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cbc031-236c-4ed1-bbe0-aff8162800bf",
   "metadata": {},
   "source": [
    "### Regression with categorical features\n",
    "music_dummies has been preloaded, along with Ridge, cross_val_score, numpy as np, and a KFold object stored as kf.\n",
    "\n",
    "The model will be evaluated by calculating the average RMSE, but first, convert the scores for each fold to positive values and take their square root. This metric shows the average error of our model's predictions, so it can be compared against the standard deviation of the target value—\"popularity\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1790554-4b0b-4932-8266-b954005ceef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "X = music_dummies.drop(\"popularity\", axis=1).values\n",
    "y = music_dummies[\"popularity\"].values\n",
    "\n",
    "# Instantiate a ridge model\n",
    "ridge = Ridge(alpha=0.2)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(ridge, X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(-scores)\n",
    "print(\"Average RMSE: {}\".format(np.mean(rmse)))\n",
    "print(\"Standard Deviation of the target array: {}\".format(np.std(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a78d9c-08dd-4ddd-a87b-f94e5d44dc15",
   "metadata": {},
   "source": [
    "## Handling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4397f14-74c0-4bb5-89ef-eb7ace894047",
   "metadata": {},
   "source": [
    "### Dropping missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928c5a37-2b9e-4949-9931-c7c1b6cc8401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print missing values for each columns\n",
    "music_df.isna().sum().sort_values()\n",
    "\n",
    "# Remove values where less than 5% are missing\n",
    "music_df = music_df.dropna(subset=['genre', 'popularity', 'loudness', 'liveness', 'tempo'])\n",
    "\n",
    "# Convert genre to a binary feature\n",
    "music_df[\"genre\"] = np.where(music_df[\"genre\"] == \"Rock\", 1, 0)\n",
    "\n",
    "print(music_df.isna().sum().sort_values())\n",
    "print(\"Shape of the `music_df`: {}\".format(music_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2ccfe7-acfe-48e0-98a7-f7fe861718ee",
   "metadata": {},
   "source": [
    "### Pipeline for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d43b9-b574-4233-a7e5-79672c357b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Instantiate an imputer\n",
    "imputer = SimpleImputer()\n",
    "\n",
    "# Instantiate a knn model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Build steps for the pipeline\n",
    "steps = [(\"imputer\", imputer), \n",
    "         (\"knn\", knn)]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59c87e2-25f6-4bf1-ad77-a76a879ce5ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Centering and scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1465f99-e2b0-4c67-ad0b-3bc49a288049",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scaling in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cfcb5c-b481-4974-be21-402f50545f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = music_df.drop(\"genre\", axis=1).values\n",
    "y = music_df[\"genre\"].values\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(np.mean(X), np.std(X))\n",
    "print(np.mean(X_train_scaled), np.std(X_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af2909-934f-4031-9969-10a08d89a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps [('scaler'), StandardScaler()),\n",
    "       ('knn', KNeighborsClassifier(n_neighbors=6))]\n",
    "pipeline = Pipeline(steps)\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "\n",
    "knn_scaled = pipeline.fit(X_train, y_train)\n",
    "y_pred = knn_scaled.predict(X_test)\n",
    "print(knn_scaled.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e73a01-ce0d-4aa7-9392-3dc385d1ea80",
   "metadata": {},
   "source": [
    "#### Comparing performance using unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02fbe6a-6863-4ab0-befd-38336170f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "\n",
    "knn_unscaled = KNeighborsClassifier(n_neighbors=6).fit(X_train, y_train)\n",
    "print(knn_unscaled.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f5f3b1-fb9f-4085-8ea5-af7980a1770c",
   "metadata": {},
   "source": [
    "### Centering and scaling for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693852b7-3d51-47d5-a9e3-ce229503083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create pipeline steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"lasso\", Lasso(alpha=0.5))]\n",
    "\n",
    "# Instantiate the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate and print R-squared\n",
    "print(pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff94fcc-897c-4030-81ea-a215513731f4",
   "metadata": {},
   "source": [
    "### Centering and scaling for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9f7eae-6d9a-448d-bb6f-7f7ca4b6d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the steps\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"logreg\", LogisticRegression())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create the parameter space\n",
    "parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "\n",
    "# Instantiate the grid search object\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "# Fit to the training data\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43a724a-27d4-458f-b73b-3a73a56af1c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34729acb-39e0-448d-89d3-6836cf2be7be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4c58f89-7971-40dd-84dd-8a18cb16c98e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3304b66-3a34-403b-a85f-882ff55cc16d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
